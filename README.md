# TitanicDataset_with_Spark_Project
Use of Apache Spark to predict the survival of Titanic passengers. PySpark and MLlib have been used to manage Spark DataFrames in Python and build various Machine Learning models for classification. The models built are: Logistic Regression, Decision Tree, Random Forest and Gradient Boosted Tree.

The data pipeline consists on:
1. Data loading
2. Data profiling
3. Exploratory Data Analysis (EDA)
4. Data preprocessing
5. Development of Machine Learning Models
6. Comparison of metrics
