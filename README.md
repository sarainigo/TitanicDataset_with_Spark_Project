# TitanicDataset_with_Spark_Project
Use of Apache Spark to predict the survival of Titanic passengers. PySpark and MLlib have been used to manage DataFrames and build various Machine Learning models

The data pipeline consists on:
1. Data loading
2. Data profiling
3. Exploratory Data Analysis (EDA)
4. Data preprocessing
5. Development of Machine Learning Models
